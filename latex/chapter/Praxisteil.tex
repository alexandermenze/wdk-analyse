\section{Praxisteil}
% CRISP DM
% Hier noch mal beschreiben das lediglich der Effekt nachgewiesen werden soll, nicht belegt
% Im Zusammenhang mit Nutzung von Indizes erläutern (Grundlage rechtfertigen)

% Optimierung: Jeden Index in ein eigenes Cluster, dann Index weg

Im Praxisteil dieser Arbeit soll zuerst das Problem beschrieben werden und wie es fachlich gelöst werden kann. Dazu gehört auch die Auswahl der Werkzeuge für die Umsetzung. Anschließend folgt die Strukturierung und Planung der Daten. Dies beinhaltet die Erstellung einer begründeten Datenstruktur. In dem Kapitel der \nameref{sec:datenvorbereitung} geht es dann um die Beschaffung, Aufbereitung und das Einlesen der Quelldaten in die Datenbank. Abschließend wird die Auswertung durchgeführt.

\subsection{Problemverständnis und Planung}
% Die konkreten Berechnungen hier einfügen
% Welche Daten werden benötigt?
% Welche Werkzeuge sollen genutzt werden (Wie sollen die Daten angezeigt werden um das Problem zu erläutern?)
% Mengen und Frequenzen von Daten

% anhand von großen Indizes um die Marktentwicklung insgesamt zu betrachten und nicht auf einzelne Aktien zu sehen
% In verschiedenen Ländern und Regionen (ob es Unterschiede gibt)
% Das soll über mehrere Zeiträume analysiert werden um wirklich eine Aussage treffen zu können
% Dazu werden die Daten historisch analysiert (soweit wie diese zurückgehen)
% Benötigt werden die täglichen Kursentwicklungen
% Berechnet wird die Kursentwicklung eines Tages mit der Formel (Schlusskurs Tag - Schlusskurs letzter Tag)
% Das ganze kann dann addiert werden nach Wochentagen um eine Gesamtstatistik zu erhalten

In dieser Auswertung soll untersucht werden ob der Weekend Effect in verschiedenen Regionen aufgetreten ist. Falls er existiert, ist ebenfalls interessant ob der Effekt je nach Zeitraum in der Vergangenheit unterschiedlich ausgeprägt war. Dafür werden historische Daten von yahoo Finance mit der Programmiersprache Python und der Datenbank OrientDB ausgewertet. Um bei der Auswertung möglichst die gesamte Entwicklung eines Marktes einzufangen und nicht Anomalien in den Kursverläufen einzelner Aktien zu untersuchen werden dafür ausschließlich Daten von breiter aufgestellten Aktienindizes verwendet. Benötigt werden dazu für jeden zu untersuchenden Index tägliche Daten. Diese sollten den Tagesschlusskurs, also den Kurs bei Schließung der Börse, und das Tagesdatum enthalten. Dann kann durch das Iterieren über alle Tage jeweils aus dem Schlusskurs des Vortages und dem Schlusskurs des aktuellen Tages die Differenz gebildet werden. Diese Differenzen nach Wochentagen summiert ergeben dann die absoluten Kursveränderungen an den jeweiligen Tagen. Diese sollen anschließend mit der Python Bibliothek \enquote{matplotlib} visualisiert und verglichen werden.

Außerdem ist interessant ob bestimmte Wochentage insgesamt häufiger positiv oder negativ ausfallen. Dafür müssen alle Tage je nach Kursentwicklung gezählt werden. Auch dies soll grafisch dargestellt werden.

% Bibliotheken
% Normalisierung der Ergebnisse?

\subsection{Datenverständnis}
% Datenstruktur und Format, Menge, Zeitauflösung etc.
% Was ist die ISIN?
% Wie und warum habe ich aufgebaut
% Adj_Close vs Close

% Daten kommen von yahoo Finance

Die Daten für die Auswertung kommen von yahoo Finance. Um diese dauerhaft zur späteren Nachverfolgbarkeit zu behalten, wurde der Download als \gls{CSV} Datei statt der \gls{HTTP}-Schnittstelle gewählt. Es wurden Datensätze für die folgenden Aktienindizes gespeichert:

\begin{itemize}
    \item DAX (Deutscher Aktienindex) - Die größten 30 Unternehmen an deutschen Börsen. Daten seit 1987.
    \item Dow Jones Industrial Average - Die größten 30 Unternehmen an amerikanischen Börsen. Daten seit 1992.
    \item CAC40 - Die größten 40 Unternehmen an der Pariser Börse. Daten seit 1980.
    \item S\&P 500 - Die größten 500 Unternehmen an amerikanischen Börsen. Daten seit 1970.
    \item Euronext 100 - Die größten 100 börsennotierten Unternehmen aus den Ländern Frankreich, den Niederlanden, Belgien, Irland und Portugal. Daten seit 2000.
\end{itemize}

Für jeden Handelstag an der jeweils lokalen Börse existiert ein Datensatz. Diese enthalten das Datum des Tages, den Kurs bei Öffnung der Börse, den Kurs bei Schließung der Börse, das Maximum und Minimum an diesem Tag und das Handelsvolumen. Außerdem wird eine bereinigter Schlusskurs angegeben. Dieser rechnet Einflüsse wie Gewinnausschüttungen oder die Teilung von Aktien\footnote{Wenn ein Aktienpreis zu hoch steigt, kann das Unternehmen seine Aktien teilen. Bei einer 2:1 Teilung wird die Menge der Aktien verdoppelt und dafür der Preis halbiert. Aktien können auch andersherum zusammengeführt werden.} aus dem Schlusskurs heraus um Kurssprünge zu vermeiden. Für die Datenanalyse werden lediglich das Datum, der Öffnungs- und bereinigte Schlusskurs benötigt.

% Wenn keine Ideen mehr Beispieldatensatz einfügen

\subsection{Datenbankvorbereitung}
% Einlesen der Daten und Aufbereitung
%   Behandeln von Ausreißern und fehlenden Daten zwischen den Datensätzen
%   Wie geht man mit unterschiedlicher Anzahl Wochentagen um? (Normalisierung)
% Format der Dokumente und Wahl der Tabellen
% ISIN
% CSV Format
% Schreiben der Daten in die Datenbank
% Erstellung des Datenbankindex
% Konfiguration

Um die Daten einlesen zu können musste zuerst die Datenbank aufgesetzt werden. Diese wurde als Docker Container gehostet. Da es Inkompatibilitäten zwischen der Bibliothek PyOrient und der neusten Version der Datenbank gibt, wurde die Version 2.2.35 von OrientDB genutzt. Die Verbindungs- und Anmeldedaten werden zur Laufzeit des Python Skriptes aus einer \gls{YAML}-Konfigurationsdatei geladen. Um die Erstellung der Datenbank zu vereinfachen, wurde sie im Quellcode erledigt. Dies ist im Listing \ref{list:create_db} zu sehen. In Zeile eins und zwei wird die Datenbank gelöscht, falls sie existiert. Da hier unabhängige Datensätze ohne Verknüpfungen gespeichert werden sollen, wurde sich für das dokumentenbasierte Modell entschieden. Dies ist in Zeile vier bei der Erstellung der Datenbank zu sehen. Der Parameter \texttt{STORAGE\_TYPE\_PLOCAL} gibt an, das der Inhalt auf der Festplatte gespeichert werden soll. Alternativ könnte OrientDB die Daten auch ausschließlich im Arbeitsspeicher halten. Da die Daten allerdings persistent gespeichert werden sollen, wurde hier nicht diese Option gewählt. In Zeile sechs ist die Erstellung der neuen Klasse zu sehen. Die Variable \texttt{self.table\_index\_values\_name} ist ebenfalls in der Konfigurationsdatei definiert und gibt den Namen der Klasse an. Zusätzlich zur Klasse wird hier die Eigenschaft \texttt{Date} mit dem Datentyp \texttt{DATE} definiert. Dies gehört zum Schema der Klasse und wird benötigt, da OrientDB das Datumsfeld sonst als Zeichenkette interpretieren würde.

\begin{figure}[!htb]
    \begin{lstlisting}[caption=Anlegen und initialiseren einer Datenbank in Python, label=list:create_db]
if self.client.db_exists(self.db_name):
    self.client.db_drop(self.db_name)

self.client.db_create(self.db_name, pyorient.DB_TYPE_DOCUMENT, pyorient.STORAGE_TYPE_PLOCAL)
self.database = self.client.db_open(self.db_name, self.username, self.password)
self.client.command("CREATE CLASS " + self.table_index_values_name + " IF NOT EXISTS")
self.client.command("CREATE PROPERTY " + self.table_index_values_name + ".Date DATE")
    \end{lstlisting}
\end{figure}

\subsection{Datenvorbereitung}
\label{sec:datenvorbereitung}

Um die Einpflege der Daten zu automatisieren, wurde eine zweite Konfigurationsdatei mit den einer Liste an Pfaden der einzelnen Dateien und eindeutigen Id's angelegt. Beispielhaft ist der Eintrag des DAX in Listing \ref{list:config_dax} zu sehen. Als eindeutige Id, unter der später die Datensätze in der Datenbank auseinander gehalten werden sollen, wurde die \gls{ISIN} gewählt. Diese stellt eine weltweit eindeutige Bezeichnung für Wertpapierprodukte dar.

\begin{figure}[!htb]
    \begin{lstlisting}[caption=Konfigeintrag des DAX, label=list:config_dax]
- file_name: "Index DAX Entwicklung.csv"
  isin: "DE0008469008"
    \end{lstlisting}
\end{figure}

Als nächstes wurde sich mit der Aufbereitung und dem Einpflegen in die Datenbank beschäftigt. Dies soll nach dem \gls{ETL} Prozess geschehen. Das bedeutet zuerst werden die Daten aus der Ursprungsquelle extrahiert. Dann werden sie transformiert, also auf die spätere Nutzung angepasst. Als letztes werden die Daten in die Zieldatenbank geschrieben. Um die Daten zuerst auszulesen, wurde die Python Bibliothek \enquote{pandas} verwendet. Diese erlaubt das Lesen von tabellarischen Daten aus einer Vielzahl an Datenformaten und Quellen. Dafür wird durch die Liste der Datendateien in der Konfigurationsdatei iteriert. Jede Datei wird über den Befehl \texttt{pandas.read\_csv(path)} als DataFrame in den Arbeitsspeicher geladen. Die Daten können dann wie in Listing \ref{list:transformation} transformiert werden. Dazu gehört die Entfernung der Leerzeichen aus den Spaltennamen, wie in Zeile eins dargestellt. Diese sind in OrientDB nicht erlaubt. Außerdem sollen, wenn verfügbar, immer die bereinigten Schlusskurse verwendet werden. Dafür werden sie entfernt.

% Entscheidung Cluster, Index

\begin{figure}[!htb]
    \begin{lstlisting}[caption=Transformation eines DataFrames, label=list:transformation]
df.columns = df.columns.str.replace(' ', '_')

if "Adj_Close" in df.columns:
    df["Close"] = df["Adj_Close"]

df.drop(['High', 'Low', 'Adj_Close', 'Volume'], axis=1, errors='ignore', inplace=True)
df.dropna(inplace=True)
    \end{lstlisting}
\end{figure}

\subsection{Auswertung der Daten}
% Laden der Daten aus der Datenbank
% Generierung der Auswertung mit Verweis auf das Problemverständnis
% Erstellung der Grafiken
% Zahlenoutput der Auswertung
% Problematisch wenn Daten fehlen? null, null, null etc.

\clearpage